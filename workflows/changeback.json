{
  "10": {
    "inputs": {
      "sampler_state": "Sample",
      "seed": 169886438006392,
      "steps": 20,
      "cfg": 4.20001220703125,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "11",
        0
      ],
      "positive": [
        "90",
        0
      ],
      "negative": [
        "11",
        2
      ],
      "latent_image": [
        "24",
        0
      ],
      "optional_vae": [
        "11",
        4
      ]
    },
    "class_type": "KSampler (Efficient)"
  },
  "11": {
    "inputs": {
      "ckpt_name": "dreamshaper_8.safetensors",
      "vae_name": "Baked VAE",
      "clip_skip": -5,
      "lora_name": "None",
      "lora_model_strength": 1,
      "lora_clip_strength": 1.1119998168945313,
      "positive": "",
      "negative": "",
      "empty_latent_width": 512,
      "empty_latent_height": 512,
      "batch_size": 1
    },
    "class_type": "Efficient Loader"
  },
  "12": {
    "inputs": {
      "image": "36901875fd7c43458143714c435cf1a6.jpg",
      "choose file to upload": "image"
    },
    "class_type": "LoadImage"
  },
  "13": {
    "inputs": {
      "transparency": "true",
      "images": [
        "29",
        0
      ]
    },
    "class_type": "Image Rembg (Remove Background)"
  },
  "15": {
    "inputs": {
      "images": [
        "13",
        0
      ]
    },
    "class_type": "PreviewImage"
  },
  "17": {
    "inputs": {
      "method": "alpha",
      "image": [
        "13",
        0
      ]
    },
    "class_type": "Image To Mask"
  },
  "20": {
    "inputs": {
      "threshold": 1,
      "mask": [
        "17",
        0
      ]
    },
    "class_type": "ToBinaryMask"
  },
  "22": {
    "inputs": {
      "mask": [
        "20",
        0
      ]
    },
    "class_type": "InvertMask"
  },
  "24": {
    "inputs": {
      "grow_mask_by": 6,
      "pixels": [
        "29",
        0
      ],
      "vae": [
        "11",
        4
      ],
      "mask": [
        "22",
        0
      ]
    },
    "class_type": "VAEEncodeForInpaint"
  },
  "29": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 512,
      "height": 512,
      "crop": "center",
      "image": [
        "12",
        0
      ]
    },
    "class_type": "ImageScale"
  },
  "39": {
    "inputs": {
      "text": "old , old and dirty, aged, covered in dust",
      "clip": [
        "11",
        5
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "41": {
    "inputs": {
      "strength": 0.75,
      "conditioning": [
        "39",
        0
      ],
      "control_net": [
        "42",
        0
      ],
      "image": [
        "44",
        0
      ]
    },
    "class_type": "ControlNetApply"
  },
  "42": {
    "inputs": {
      "control_net_name": "softedge.safetensors"
    },
    "class_type": "ControlNetLoader"
  },
  "44": {
    "inputs": {
      "version": "v1.1",
      "safe": "enable",
      "image": [
        "29",
        0
      ]
    },
    "class_type": "HEDPreprocessor"
  },
  "45": {
    "inputs": {
      "sampler_state": "Sample",
      "seed": 418771959735739,
      "steps": 20,
      "cfg": 3.5999755859375,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.4259991455078122,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "10",
        0
      ],
      "positive": [
        "57",
        0
      ],
      "negative": [
        "10",
        2
      ],
      "latent_image": [
        "10",
        3
      ],
      "optional_vae": [
        "10",
        4
      ]
    },
    "class_type": "KSampler (Efficient)"
  },
  "57": {
    "inputs": {
      "strength": 0.25,
      "conditioning": [
        "39",
        0
      ],
      "control_net": [
        "58",
        0
      ],
      "image": [
        "59",
        0
      ]
    },
    "class_type": "ControlNetApply"
  },
  "58": {
    "inputs": {
      "control_net_name": "softedge.safetensors"
    },
    "class_type": "ControlNetLoader"
  },
  "59": {
    "inputs": {
      "version": "v1.1",
      "safe": "enable",
      "image": [
        "10",
        5
      ]
    },
    "class_type": "HEDPreprocessor"
  },
  "70": {
    "inputs": {
      "resize_behavior": "source_size",
      "image_base": [
        "29",
        0
      ],
      "image_to_paste": [
        "45",
        5
      ],
      "mask": [
        "80",
        0
      ]
    },
    "class_type": "Paste By Mask"
  },
  "71": {
    "inputs": {
      "model_name": "bbox/face_yolov8s.pt"
    },
    "class_type": "UltralyticsDetectorProvider"
  },
  "72": {
    "inputs": {
      "threshold": 0.5,
      "dilation": 10,
      "crop_factor": 3,
      "drop_size": 10,
      "bbox_detector": [
        "71",
        0
      ],
      "image": [
        "29",
        0
      ]
    },
    "class_type": "BboxDetectorSEGS"
  },
  "73": {
    "inputs": {
      "detection_hint": "center-1",
      "dilation": 0,
      "threshold": 0.93,
      "bbox_expansion": 0,
      "mask_hint_threshold": 0.7,
      "mask_hint_use_negative": "False",
      "sam_model": [
        "74",
        0
      ],
      "segs": [
        "72",
        0
      ],
      "image": [
        "29",
        0
      ]
    },
    "class_type": "SAMDetectorCombined"
  },
  "74": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader"
  },
  "75": {
    "inputs": {
      "mask": [
        "73",
        0
      ]
    },
    "class_type": "MaskToImage"
  },
  "78": {
    "inputs": {
      "image": [
        "75",
        0
      ]
    },
    "class_type": "ImageInvert"
  },
  "79": {
    "inputs": {
      "filename_prefix": "background",
      "images": [
        "70",
        0
      ]
    },
    "class_type": "SaveImage"
  },
  "80": {
    "inputs": {
      "radius": 10,
      "sigma_factor": 1,
      "image": [
        "78",
        0
      ]
    },
    "class_type": "Blur"
  },
  "89": {
    "inputs": {
      "control_net_name": "color.pth"
    },
    "class_type": "ControlNetLoader"
  },
  "90": {
    "inputs": {
      "strength": 0.6699999999999999,
      "conditioning": [
        "41",
        0
      ],
      "control_net": [
        "89",
        0
      ],
      "image": [
        "91",
        0
      ]
    },
    "class_type": "ControlNetApply"
  },
  "91": {
    "inputs": {
      "image": [
        "29",
        0
      ]
    },
    "class_type": "ColorPreprocessor"
  }
}